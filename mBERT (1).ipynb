{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d74e7c7f2454430f84beb38e8b0b7e8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c6bbd3cc273444c93770acba3f2c072",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_91a435f3ad134ed0bdf7ea6c212d0f83",
              "IPY_MODEL_64b52bb2321f4ad4b597fb8ddbc010c3"
            ]
          }
        },
        "6c6bbd3cc273444c93770acba3f2c072": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "91a435f3ad134ed0bdf7ea6c212d0f83": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e6dd6afba1b04eef8c46cffe0fbcc5f8",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7416613381334161b1c69b6cf0dd8196"
          }
        },
        "64b52bb2321f4ad4b597fb8ddbc010c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b4af065143544ddb9a975978fbcec42a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 2.01MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2ed5c6b72a56477db881550994088fe0"
          }
        },
        "e6dd6afba1b04eef8c46cffe0fbcc5f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7416613381334161b1c69b6cf0dd8196": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b4af065143544ddb9a975978fbcec42a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2ed5c6b72a56477db881550994088fe0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b044889ef81743b3b8899307196573bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_01395834e0dd45368120a5a4eea45bbf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_64e33aae706849cdb96b06791c384c59",
              "IPY_MODEL_9ddfd7dd2ad54a148efe44b190e45b67"
            ]
          }
        },
        "01395834e0dd45368120a5a4eea45bbf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "64e33aae706849cdb96b06791c384c59": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_de339ec1c24a43bcbcaa8ae01d1e95fa",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0860f4ee274a4f4ab976d7040bf448e2"
          }
        },
        "9ddfd7dd2ad54a148efe44b190e45b67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_68ce5f78b9b2485087eb5ad6b40a3834",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:00&lt;00:00, 2.07kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6b559fddefbb4b7f9e3a775812c71670"
          }
        },
        "de339ec1c24a43bcbcaa8ae01d1e95fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0860f4ee274a4f4ab976d7040bf448e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "68ce5f78b9b2485087eb5ad6b40a3834": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6b559fddefbb4b7f9e3a775812c71670": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0586ac838f914d14b3fc216aa5e3e626": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1418cda0c7af4ff18d8376a33e7cafdb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_61cc188fd9224b5db5152fdd69c8cdc2",
              "IPY_MODEL_3043fb9d5ae34b4d8b918505ca3b462f"
            ]
          }
        },
        "1418cda0c7af4ff18d8376a33e7cafdb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "61cc188fd9224b5db5152fdd69c8cdc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a67caaf3d94b4b388595638ca012831b",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 714314041,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 714314041,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bb893bf18184ae79586f74623a82548"
          }
        },
        "3043fb9d5ae34b4d8b918505ca3b462f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e93854864eb5460b9d8120e9a6df78c7",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 714M/714M [01:21&lt;00:00, 8.79MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a7a932650574be4acb4e0de8226b552"
          }
        },
        "a67caaf3d94b4b388595638ca012831b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bb893bf18184ae79586f74623a82548": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e93854864eb5460b9d8120e9a6df78c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a7a932650574be4acb4e0de8226b552": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A2iiXnkn63Ao",
        "outputId": "679863be-0f07-40d0-c4a2-7ef9308009e6"
      },
      "source": [
        "import torch\r\n",
        "import time\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset,DataLoader\r\n",
        "import pandas as pd\r\n",
        "!pip install transformers\r\n",
        "from transformers import BertModel, BertTokenizer\r\n",
        "from torch import cuda\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/0c/7d5950fcd80b029be0a8891727ba21e0cd27692c407c51261c3c921f6da3/transformers-4.1.1-py3-none-any.whl (1.5MB)\n",
            "\u001b[K     |████████████████████████████████| 1.5MB 9.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.4)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 16.5MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 18.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=6ee49a9443c57ae754cc1a2abe1f4ca690f17108b20b76741d4373663a402b6e\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.1.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "_V75SGMM7rh6",
        "outputId": "69e2f026-9759-4767-beaf-5d64491b2938"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/yasaswinik12/LSTM_datasets/main/tamil_offensive_full_train.csv?token=AOSGB3OJ3JWGZ6WLNKU6YSS74HX3Q'\r\n",
        "df = pd.read_csv(url, delimiter='\\t', names=['sentence','classes','nan'])\r\n",
        "df = df.drop(columns=['nan'])\r\n",
        "df.head(9)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ippo intha trailer ah parkuravana oru like pod...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>En thalaivan yogi babu irukkaar. Padam vera le...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Nerkonda parvai...  Sema sema sema trailer</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence        classes\n",
              "0                  movie vara level la Erika poguthu  Not_offensive\n",
              "1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil\n",
              "2          Padam nalla comedy padama irukum polaye..  Not_offensive\n",
              "3  karthick subburaj anne .... intha padam vetri ...  Not_offensive\n",
              "4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive\n",
              "5  ippo intha trailer ah parkuravana oru like pod...  Not_offensive\n",
              "6  En thalaivan yogi babu irukkaar. Padam vera le...  Not_offensive\n",
              "7         Nerkonda parvai...  Sema sema sema trailer  Not_offensive\n",
              "8     ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THR2BY2C7u4d",
        "outputId": "6f9d1269-067f-4ed3-c5f6-d8015132d937"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence    35139\n",
              "classes     35139\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1OHweYg73yo",
        "outputId": "cf1a8df0-37f4-4fa6-c689-ccde649d6cd3"
      },
      "source": [
        "df['classes'].apply(len).max()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMXROKFJ77uF",
        "outputId": "940a2c69-802c-4de3-f7fb-5f985e68d3a2"
      },
      "source": [
        "df['sentence'].apply(len).max()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvGPUoay796S",
        "outputId": "95a103d2-869b-49a9-d182-00a1ab4ea2db"
      },
      "source": [
        "df['classes'].unique()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Not_offensive', 'not-Tamil', 'Offensive_Targeted_Insult_Other',\n",
              "       'Offensive_Targeted_Insult_Group', 'Offensive_Untargetede',\n",
              "       'Offensive_Targeted_Insult_Individual'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "PGfC25Jp8AdL",
        "outputId": "ff151630-900c-45d7-f9e7-63fa00d10dea"
      },
      "source": [
        "encode_dict = {}\r\n",
        "\r\n",
        "def encode_cat(x):\r\n",
        "  if x not in encode_dict.keys():\r\n",
        "    encode_dict[x] = len(encode_dict)\r\n",
        "  return encode_dict[x]\r\n",
        "\r\n",
        "df['encode_cat'] = df['classes'].apply(lambda x: encode_cat(x))\r\n",
        "df.head(9)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>classes</th>\n",
              "      <th>encode_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ippo intha trailer ah parkuravana oru like pod...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>En thalaivan yogi babu irukkaar. Padam vera le...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Nerkonda parvai...  Sema sema sema trailer</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence        classes  encode_cat\n",
              "0                  movie vara level la Erika poguthu  Not_offensive           0\n",
              "1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil           1\n",
              "2          Padam nalla comedy padama irukum polaye..  Not_offensive           0\n",
              "3  karthick subburaj anne .... intha padam vetri ...  Not_offensive           0\n",
              "4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive           0\n",
              "5  ippo intha trailer ah parkuravana oru like pod...  Not_offensive           0\n",
              "6  En thalaivan yogi babu irukkaar. Padam vera le...  Not_offensive           0\n",
              "7         Nerkonda parvai...  Sema sema sema trailer  Not_offensive           0\n",
              "8     ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க  Not_offensive           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "1KH0SFhF8f69",
        "outputId": "a71abad4-844a-4cc8-f420-52543de778fd"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "sns.countplot(df.encode_cat)\r\n",
        "plt.xlabel('classes');"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 458
        },
        "id": "cqkk28Tv8ErH",
        "outputId": "57125cc7-507a-4929-94f8-303a9515532a"
      },
      "source": [
        "# import imblearn\r\n",
        "# from collections import Counter\r\n",
        "# from matplotlib import pyplot\r\n",
        "# X = df['sentence']\r\n",
        "# y = df['encode_cat']\r\n",
        "# counter = Counter(y)\r\n",
        "# for k,v in counter.items():\r\n",
        "# \tper = v / len(y) * 100\r\n",
        "# \tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\r\n",
        "# # plot the distribution\r\n",
        "# pyplot.bar(counter.keys(), counter.values())\r\n",
        "# pyplot.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Class=0, n=25425 (72.356%)\n",
            "Class=1, n=1454 (4.138%)\n",
            "Class=2, n=454 (1.292%)\n",
            "Class=3, n=2557 (7.277%)\n",
            "Class=4, n=2906 (8.270%)\n",
            "Class=5, n=2343 (6.668%)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYMAAAD4CAYAAAAO9oqkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAPhUlEQVR4nO3df4hdZ53H8fdnk9aVqjTa2RCSsCkahChsrEMaqCyusmlaZVNBpAXbIF0jmLLKCmv0n7hqof6hrgUtRBtMWNdssUqDRmPoFqSwbTOpsW0a3Q41pQmxGU21iqCkfveP+wx7N97JTOZO5s6P9wsu99zvfc6534fSfuac89zbVBWSpMXtLwbdgCRp8AwDSZJhIEkyDCRJGAaSJGDpoBuYrquuuqrWrFkz6DYkaV45cuTIL6tq6Pz6vA2DNWvWMDIyMug2JGleSfJcr7qXiSRJhoEkyTCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CSxBS+gZxkNbAXWA4UsKuqvpTkU8AHgbE29JNVdaDt8wngduBl4J+q6mCrbwa+BCwBvlZVd7X61cA+4HXAEeDWqvrjTE3yfGt2fO9SHXpGnbjrXYNuQdIiMZUzg3PAx6pqHbAR2J5kXXvvi1W1vj3Gg2AdcDPwJmAz8JUkS5IsAb4M3ACsA27pOs7n2rHeALxIJ0gkSbNk0jCoqtNV9Xjb/i1wHFh5gV22APuq6g9V9XNgFNjQHqNV9Wz7q38fsCVJgHcA32r77wFumu6EJEkX76LuGSRZA7wFeLSV7kjyRJLdSZa12krg+a7dTrbaRPXXAb+uqnPn1Xt9/rYkI0lGxsbGeg2RJE3DlMMgyauA+4GPVtVLwD3A64H1wGng85ekwy5VtauqhqtqeGjoz36BVZI0TVP6Ceskl9EJgm9U1bcBquqFrve/Cny3vTwFrO7afVWrMUH9V8CVSZa2s4Pu8ZKkWTDpmUG7pn8vcLyqvtBVX9E17D3AU217P3Bzkle0VUJrgceAw8DaJFcnuZzOTeb9VVXAQ8B72/5bgQf6m5Yk6WJM5czgOuBW4MkkR1vtk3RWA62ns9z0BPAhgKo6luQ+4Gk6K5G2V9XLAEnuAA7SWVq6u6qOteN9HNiX5LPAj+mEjyRplkwaBlX1MJAebx24wD53Anf2qB/otV9VPUtntZEkaQD8BrIkyTCQJBkGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkMYUwSLI6yUNJnk5yLMlHWv21SQ4leaY9L2v1JLk7yWiSJ5Jc03WsrW38M0m2dtXfmuTJts/dSXIpJitJ6m0qZwbngI9V1TpgI7A9yTpgB/BgVa0FHmyvAW4A1rbHNuAe6IQHsBO4FtgA7BwPkDbmg137be5/apKkqZo0DKrqdFU93rZ/CxwHVgJbgD1t2B7gpra9BdhbHY8AVyZZAVwPHKqqs1X1InAI2Nzee01VPVJVBeztOpYkaRZc1D2DJGuAtwCPAsur6nR76xfA8ra9Eni+a7eTrXah+ske9V6fvy3JSJKRsbGxi2ldknQBUw6DJK8C7gc+WlUvdb/X/qKvGe7tz1TVrqoarqrhoaGhS/1xkrRoTCkMklxGJwi+UVXfbuUX2iUe2vOZVj8FrO7afVWrXai+qkddkjRLprKaKMC9wPGq+kLXW/uB8RVBW4EHuuq3tVVFG4HftMtJB4FNSZa1G8ebgIPtvZeSbGyfdVvXsSRJs2DpFMZcB9wKPJnkaKt9ErgLuC/J7cBzwPvaeweAG4FR4PfABwCq6mySzwCH27hPV9XZtv1h4OvAK4Hvt4ckaZZMGgZV9TAw0br/d/YYX8D2CY61G9jdoz4CvHmyXiRJl4bfQJYkGQaSJMNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJElMIQyS7E5yJslTXbVPJTmV5Gh73Nj13ieSjCb5WZLru+qbW200yY6u+tVJHm31/0xy+UxOUJI0uamcGXwd2Nyj/sWqWt8eBwCSrANuBt7U9vlKkiVJlgBfBm4A1gG3tLEAn2vHegPwInB7PxOSJF28ScOgqn4EnJ3i8bYA+6rqD1X1c2AU2NAeo1X1bFX9EdgHbEkS4B3At9r+e4CbLnIOkqQ+9XPP4I4kT7TLSMtabSXwfNeYk602Uf11wK+r6tx5dUnSLJpuGNwDvB5YD5wGPj9jHV1Akm1JRpKMjI2NzcZHStKiMK0wqKoXqurlqvoT8FU6l4EATgGru4auarWJ6r8Crkyy9Lz6RJ+7q6qGq2p4aGhoOq1LknqYVhgkWdH18j3A+Eqj/cDNSV6R5GpgLfAYcBhY21YOXU7nJvP+qirgIeC9bf+twAPT6UmSNH1LJxuQ5JvA24GrkpwEdgJvT7IeKOAE8CGAqjqW5D7gaeAcsL2qXm7HuQM4CCwBdlfVsfYRHwf2Jfks8GPg3hmbnSRpSiYNg6q6pUd5wv9gV9WdwJ096geAAz3qz/J/l5kkSQPgN5AlSYaBJMkwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkiSmEQZLdSc4keaqr9tokh5I8056XtXqS3J1kNMkTSa7p2mdrG/9Mkq1d9bcmebLtc3eSzPQkJUkXNpUzg68Dm8+r7QAerKq1wIPtNcANwNr22AbcA53wAHYC1wIbgJ3jAdLGfLBrv/M/S5J0iU0aBlX1I+DseeUtwJ62vQe4qau+tzoeAa5MsgK4HjhUVWer6kXgELC5vfeaqnqkqgrY23UsSdIsme49g+VVdbpt/wJY3rZXAs93jTvZaheqn+xR7ynJtiQjSUbGxsam2bok6Xx930Buf9HXDPQylc/aVVXDVTU8NDQ0Gx8pSYvCdMPghXaJh/Z8ptVPAau7xq1qtQvVV/WoS5Jm0XTDYD8wviJoK/BAV/22tqpoI/CbdjnpILApybJ243gTcLC991KSjW0V0W1dx5IkzZKlkw1I8k3g7cBVSU7SWRV0F3BfktuB54D3teEHgBuBUeD3wAcAqupsks8Ah9u4T1fV+E3pD9NZsfRK4PvtIUmaRZOGQVXdMsFb7+wxtoDtExxnN7C7R30EePNkfUiSLh2/gSxJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJGAaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiQMA0kShoEkCcNAkoRhIEnCMJAkYRhIkjAMJEkYBpIkDANJEoaBJAnDQJKEYSBJwjCQJGEYSJIwDCRJ9BkGSU4keTLJ0SQjrfbaJIeSPNOel7V6ktydZDTJE0mu6TrO1jb+mSRb+5uSJOlizcSZwd9V1fqqGm6vdwAPVtVa4MH2GuAGYG17bAPugU54ADuBa4ENwM7xAJEkzY5LcZloC7Cnbe8Bbuqq762OR4Ark6wArgcOVdXZqnoROARsvgR9SZIm0G8YFPDDJEeSbGu15VV1um3/AljetlcCz3fte7LVJqr/mSTbkowkGRkbG+uzdUnSuKV97v+2qjqV5K+AQ0l+2v1mVVWS6vMzuo+3C9gFMDw8PGPHlaTFrq8zg6o61Z7PAN+hc83/hXb5h/Z8pg0/Bazu2n1Vq01UlyTNkmmHQZIrkrx6fBvYBDwF7AfGVwRtBR5o2/uB29qqoo3Ab9rlpIPApiTL2o3jTa0mSZol/VwmWg58J8n4cf6jqn6Q5DBwX5LbgeeA97XxB4AbgVHg98AHAKrqbJLPAIfbuE9X1dk++pIkXaRph0FVPQv8TY/6r4B39qgXsH2CY+0Gdk+3F0lSf/wGsiTJMJAkGQaSJAwDSRKGgSQJw0CShGEgScIwkCRhGEiSMAwkSRgGkiT6//8ZSFqk1uz43qBbmJITd71r0C3MC54ZSJIMA0mSl4mkWeElFc11nhlIkjwzkCTw7M0zA0mSYSBJMgwkSRgGkiQMA0kShoEkCZeWLgiLfUmcpP55ZiBJMgwkSYaBJAnDQJKEYSBJwjCQJGEYSJLwewaao/zuhDS75syZQZLNSX6WZDTJjkH3I0mLyZwIgyRLgC8DNwDrgFuSrBtsV5K0eMyJMAA2AKNV9WxV/RHYB2wZcE+StGikqgbdA0neC2yuqn9sr28Frq2qO84btw3Y1l6+EfjZrDZ6YVcBvxx0EzNooc0HFt6cFtp8YOHNaS7O56+rauj84ry6gVxVu4Bdg+6jlyQjVTU86D5mykKbDyy8OS20+cDCm9N8ms9cuUx0Cljd9XpVq0mSZsFcCYPDwNokVye5HLgZ2D/gniRp0ZgTl4mq6lySO4CDwBJgd1UdG3BbF2tOXr7qw0KbDyy8OS20+cDCm9O8mc+cuIEsSRqsuXKZSJI0QIaBJMkw6NdC+xmNJLuTnEny1KB7mQlJVid5KMnTSY4l+cige+pXkr9M8liSn7Q5/euge5oJSZYk+XGS7w66l5mQ5ESSJ5McTTIy6H4m4z2DPrSf0fgf4O+Bk3RWRd1SVU8PtLE+JPlb4HfA3qp686D76VeSFcCKqno8yauBI8BN8/yfUYArqup3SS4DHgY+UlWPDLi1viT5Z2AYeE1VvXvQ/fQryQlguKrm2pfOevLMoD8L7mc0qupHwNlB9zFTqup0VT3etn8LHAdWDrar/lTH79rLy9pjXv9Vl2QV8C7ga4PuZbEyDPqzEni+6/VJ5vl/aBayJGuAtwCPDraT/rVLKkeBM8Chqprvc/o34F+APw26kRlUwA+THGk/pTOnGQZaFJK8Crgf+GhVvTTofvpVVS9X1Xo639bfkGTeXtJL8m7gTFUdGXQvM+xtVXUNnV9j3t4uwc5ZhkF//BmNeaBdV78f+EZVfXvQ/cykqvo18BCwedC99OE64B/aNfZ9wDuS/PtgW+pfVZ1qz2eA79C5rDxnGQb98Wc05rh2s/Ve4HhVfWHQ/cyEJENJrmzbr6SzgOGng+1q+qrqE1W1qqrW0Pl36L+q6v0DbqsvSa5oCxZIcgWwCZjTK/QMgz5U1Tlg/Gc0jgP3zcOf0fh/knwT+G/gjUlOJrl90D316TrgVjp/bR5tjxsH3VSfVgAPJXmCzh8kh6pqQSzHXECWAw8n+QnwGPC9qvrBgHu6IJeWSpI8M5AkGQaSJAwDSRKGgSQJw0CShGEgScIwkCQB/wu6Go98wVQMyQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "d74e7c7f2454430f84beb38e8b0b7e8a",
            "6c6bbd3cc273444c93770acba3f2c072",
            "91a435f3ad134ed0bdf7ea6c212d0f83",
            "64b52bb2321f4ad4b597fb8ddbc010c3",
            "e6dd6afba1b04eef8c46cffe0fbcc5f8",
            "7416613381334161b1c69b6cf0dd8196",
            "b4af065143544ddb9a975978fbcec42a",
            "2ed5c6b72a56477db881550994088fe0"
          ]
        },
        "id": "_23H_Tww8LKI",
        "outputId": "9a1e5227-a5ed-44b0-a8ab-7afcb72c3dae"
      },
      "source": [
        "MAX_LEN = 512\r\n",
        "TRAIN_BATCH_SIZE = 16\r\n",
        "VALID_BATCH_SIZE = 16\r\n",
        "EPOCHS = 10\r\n",
        "LEARNING_RATE = 2e-5\r\n",
        "bert_multilingual = 'bert-base-multilingual-cased'\r\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_multilingual)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d74e7c7f2454430f84beb38e8b0b7e8a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI7LNJMd-zAp"
      },
      "source": [
        "class SentimentDataset(Dataset):\r\n",
        "\r\n",
        "  def __init__(self,dataframe,tokenizer,max_len):\r\n",
        "    self.len = len(dataframe)\r\n",
        "    self.data = dataframe\r\n",
        "    self.tokenizer = tokenizer\r\n",
        "    self.max_len = max_len \r\n",
        "  \r\n",
        "\r\n",
        "  def __getitem__(self,index):\r\n",
        "    sentence = str(self.data.sentence[index])\r\n",
        "    sentence = \" \".join(sentence.split())\r\n",
        "    encoding = self.tokenizer.encode_plus(\r\n",
        "        sentence,\r\n",
        "        add_special_tokens = True,\r\n",
        "        max_length = self.max_len,\r\n",
        "        padding = 'max_length',\r\n",
        "        return_token_type_ids = False,\r\n",
        "        return_tensors = 'pt',\r\n",
        "        truncation = True\r\n",
        "    )\r\n",
        "    #ids = encoding['input_ids']\r\n",
        "    #mask = encoding['attention_mask']\r\n",
        "    return {\r\n",
        "        'ids' : encoding['input_ids'].flatten(),\r\n",
        "        'mask': encoding['attention_mask'].flatten(),\r\n",
        "        'targets': torch.tensor(self.data.encode_cat[index],dtype=torch.long)\r\n",
        "    }\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return self.len"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpn0tEs_QMs",
        "outputId": "b87442e6-d7f4-473f-bad9-1c26694381b5"
      },
      "source": [
        "train_size = 0.9\r\n",
        "train_dataset = df.sample(frac=train_size,random_state=42)\r\n",
        "test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\r\n",
        "train_dataset = train_dataset.reset_index(drop=True)\r\n",
        "\r\n",
        "print('Total no of entities in the dataset: {}'.format(df.shape))\r\n",
        "print('Train dataset:{}'.format(train_dataset.shape))\r\n",
        "print('Test dataset: {}'.format(test_dataset.shape))\r\n",
        "\r\n",
        "training_set = SentimentDataset(train_dataset,tokenizer,MAX_LEN)\r\n",
        "testing_set = SentimentDataset(test_dataset,tokenizer,MAX_LEN)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of entities in the dataset: (35139, 3)\n",
            "Train dataset:(31625, 3)\n",
            "Test dataset: (3514, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74kBk3fl_WV8"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\r\n",
        "                'shuffle': True,\r\n",
        "                'num_workers': 0\r\n",
        "                }\r\n",
        "\r\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\r\n",
        "                'shuffle': True,\r\n",
        "                'num_workers': 0\r\n",
        "                }\r\n",
        "\r\n",
        "training_loader = DataLoader(training_set, **train_params)\r\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-10n2AR_aCX"
      },
      "source": [
        "class BERTClass(torch.nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(BERTClass, self).__init__()\r\n",
        "        self.l1 = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\r\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\r\n",
        "        self.dropout = torch.nn.Dropout(0.3)\r\n",
        "        self.classifier = torch.nn.Linear(768, 6)\r\n",
        "        \r\n",
        "    def forward(self, input_ids, attention_mask):\r\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\r\n",
        "        hidden_state = output_1[0]\r\n",
        "        pooler = hidden_state[:, 0]\r\n",
        "        pooler = self.pre_classifier(pooler)\r\n",
        "        pooler = torch.nn.ReLU()(pooler)\r\n",
        "        pooler = self.dropout(pooler)\r\n",
        "        output = self.classifier(pooler)\r\n",
        "        return output"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b044889ef81743b3b8899307196573bc",
            "01395834e0dd45368120a5a4eea45bbf",
            "64e33aae706849cdb96b06791c384c59",
            "9ddfd7dd2ad54a148efe44b190e45b67",
            "de339ec1c24a43bcbcaa8ae01d1e95fa",
            "0860f4ee274a4f4ab976d7040bf448e2",
            "68ce5f78b9b2485087eb5ad6b40a3834",
            "6b559fddefbb4b7f9e3a775812c71670",
            "0586ac838f914d14b3fc216aa5e3e626",
            "1418cda0c7af4ff18d8376a33e7cafdb",
            "61cc188fd9224b5db5152fdd69c8cdc2",
            "3043fb9d5ae34b4d8b918505ca3b462f",
            "a67caaf3d94b4b388595638ca012831b",
            "1bb893bf18184ae79586f74623a82548",
            "e93854864eb5460b9d8120e9a6df78c7",
            "4a7a932650574be4acb4e0de8226b552"
          ]
        },
        "id": "QlHP7C9SABBP",
        "outputId": "fea7845a-128b-430c-f3a4-a2b3289cd2a8"
      },
      "source": [
        "model = BERTClass()\r\n",
        "model.to(device)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b044889ef81743b3b8899307196573bc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0586ac838f914d14b3fc216aa5e3e626",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=714314041.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BERTClass(\n",
              "  (l1): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(119547, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
              "  (dropout): Dropout(p=0.3, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=6, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEqiVmieAFzc"
      },
      "source": [
        "# weights = [0.28, 0.96, 0.99, 0.93, 0.92, 0.94]\r\n",
        "# w = torch.tensor(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYxL7isDAiGi"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss().to(device)\r\n",
        "optimizer = optim.Adam(params= model.parameters(),lr = LEARNING_RATE)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxlqVLEEAmgw"
      },
      "source": [
        "def calcuate_accuracy(big_idx, targets):\r\n",
        "    n_correct = (big_idx==targets).sum().item()\r\n",
        "    return n_correct"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9osQKt86ApBq"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsbho4uxAsLh",
        "outputId": "a0aab41e-dd36-461b-ffd2-db6555d866e5"
      },
      "source": [
        "seed_val = 42\r\n",
        "torch.manual_seed(seed_val)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fbf90512b58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG3q32CVAvMF"
      },
      "source": [
        "def train(epoch):\r\n",
        "  \r\n",
        "  tr_loss = 0\r\n",
        "  n_correct = 0\r\n",
        "  nb_tr_steps = 0\r\n",
        "  nb_tr_examples = 0\r\n",
        "  model.train()\r\n",
        "  start_time = time.time()\r\n",
        "  for _,data in enumerate(training_loader, 0):\r\n",
        "      ids = data['ids'].to(device, dtype = torch.long)\r\n",
        "      mask = data['mask'].to(device, dtype = torch.long)\r\n",
        "      targets = data['targets'].to(device, dtype = torch.long)\r\n",
        "\r\n",
        "      outputs = model(ids, mask)\r\n",
        "      loss = loss_function(outputs, targets)\r\n",
        "      tr_loss += loss.item()\r\n",
        "      big_val, big_idx = torch.max(outputs.data, dim=1)\r\n",
        "      n_correct += calcuate_accuracy(big_idx, targets)\r\n",
        "\r\n",
        "      nb_tr_steps += 1\r\n",
        "      nb_tr_examples+=targets.size(0)\r\n",
        "      \r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss.backward()\r\n",
        "      #When using GPU\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "  print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\r\n",
        "  epoch_loss = tr_loss/nb_tr_steps\r\n",
        "  epoch_accu = (n_correct*100)/nb_tr_examples\r\n",
        "  print(f\"Training Loss Epoch: {epoch_loss}\")\r\n",
        "  print(f\"Training Accuracy Epoch: {epoch_accu}\")\r\n",
        "  end_time = time.time()\r\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "\r\n",
        "  return"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_F3w6xWA-W9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "e61de818-06b2-4320-a1cb-1b45e610a4cc"
      },
      "source": [
        "for epoch in range(EPOCHS):\r\n",
        "  train(epoch)\r\n",
        "  print()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-fa4b900166c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-5dae55bf9562>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     12\u001b[0m       \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'targets'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m       \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m       \u001b[0mtr_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-13-e8bf0a59e5f7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask)\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0moutput_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0ml1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattention_mask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moutput_1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mpooler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhidden_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    870\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    873\u001b[0m         )\n\u001b[1;32m    874\u001b[0m         \u001b[0msequence_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencoder_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    505\u001b[0m                     \u001b[0mencoder_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m                     \u001b[0mencoder_attention_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m                     \u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m                 )\n\u001b[1;32m    509\u001b[0m             \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, output_attentions)\u001b[0m\n\u001b[1;32m    445\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m         layer_output = apply_chunking_to_forward(\n\u001b[0;32m--> 447\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchunk_size_feed_forward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseq_len_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    448\u001b[0m         )\n\u001b[1;32m    449\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlayer_output\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mapply_chunking_to_forward\u001b[0;34m(forward_fn, chunk_size, chunk_dim, *input_tensors)\u001b[0m\n\u001b[1;32m   1782\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_chunks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1783\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1784\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mforward_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput_tensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mfeed_forward_chunk\u001b[0;34m(self, attention_output)\u001b[0m\n\u001b[1;32m    451\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    452\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfeed_forward_chunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 453\u001b[0;31m         \u001b[0mintermediate_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    454\u001b[0m         \u001b[0mlayer_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattention_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    455\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/models/bert/modeling_bert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, hidden_states)\u001b[0m\n\u001b[1;32m    379\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 381\u001b[0;31m         \u001b[0mhidden_states\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintermediate_act_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhidden_states\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    382\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhidden_states\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    383\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mgelu\u001b[0;34m(input)\u001b[0m\n\u001b[1;32m   1381\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhas_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1383\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 96.00 MiB (GPU 0; 14.73 GiB total capacity; 13.52 GiB already allocated; 3.88 MiB free; 13.68 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdKuZK8fBBkV"
      },
      "source": [
        "def valid(model,testing_loader):\r\n",
        "  model.eval()\r\n",
        "  n_correct = 0\r\n",
        "  n_wrong = 0\r\n",
        "  total = 0\r\n",
        "  tr_loss = 0\r\n",
        "  nb_tr_steps = 0\r\n",
        "  nb_tr_examples = 0\r\n",
        "  with torch.no_grad():\r\n",
        "    for _,data in enumerate(testing_loader,0):\r\n",
        "      ids = data['ids'].to(device,dtype = torch.long)\r\n",
        "      mask = data['mask'].to(device,dtype = torch.long)\r\n",
        "      targets = data['targets'].to(device,dtype=torch.long)\r\n",
        "      outputs = model(ids,mask).squeeze()\r\n",
        "      loss = loss_function(outputs,targets)\r\n",
        "      tr_loss += loss.item()\r\n",
        "      big_val,big_idx = torch.max(outputs.data,dim=1)\r\n",
        "      n_correct += calcuate_accuracy(big_idx,targets)\r\n",
        "      nb_tr_steps += 1\r\n",
        "      nb_tr_examples += targets.size(0)\r\n",
        "\r\n",
        "    epoch_loss = tr_loss/nb_tr_steps\r\n",
        "    epoch_accuracy = (n_correct*100)/nb_tr_examples\r\n",
        "    print(f\"Validation Loss Epoch:{epoch_loss}\")\r\n",
        "    print(f\"Validation Accuracy Epoch:{epoch_accuracy}\")\r\n",
        "\r\n",
        "    return epoch_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab3rMF6rBkM5"
      },
      "source": [
        "acc = valid(model, testing_loader)\r\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUFIkBb-BozE"
      },
      "source": [
        "def get_predictions(model, data_loader):\r\n",
        "  model = model.eval()\r\n",
        "  sentence = []\r\n",
        "  predictions = []\r\n",
        "  prediction_probs = []\r\n",
        "  real_values = []\r\n",
        "  with torch.no_grad():\r\n",
        "    for d in data_loader:\r\n",
        "      #texts = d[\"sentences\"]\r\n",
        "      ids = d[\"ids\"].to(device)\r\n",
        "      mask = d[\"mask\"].to(device)\r\n",
        "      targets = d[\"targets\"].to(device)\r\n",
        "      outputs = model(\r\n",
        "        input_ids=ids,\r\n",
        "        attention_mask=mask\r\n",
        "      )\r\n",
        "      _, preds = torch.max(outputs, dim=1)\r\n",
        "      #sentence.extend(texts)\r\n",
        "      predictions.extend(preds)\r\n",
        "      prediction_probs.extend(outputs)\r\n",
        "      real_values.extend(targets)\r\n",
        "  predictions = torch.stack(predictions).cpu()\r\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\r\n",
        "  real_values = torch.stack(real_values).cpu()\r\n",
        "  return sentence, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OXVaGFtBwnb"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(model,testing_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOXF6mUB2AG"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "print(classification_report(y_test, y_pred,zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}