{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "mBERT.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "dd3cb331bd3c4f7284476bdc6204cc39": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_3aa39587b13643d4831ac26847f9486a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d1801f975c5d43f49d91de8b6eb83dbc",
              "IPY_MODEL_2c13066d6b8f407a9c6e51b8f6a5b665"
            ]
          }
        },
        "3aa39587b13643d4831ac26847f9486a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d1801f975c5d43f49d91de8b6eb83dbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b9f71ca9bf374a92a5f4aa7875b2875d",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 995526,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 995526,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_70eaa94bedd748ccb3b8f6c3eea49d7b"
          }
        },
        "2c13066d6b8f407a9c6e51b8f6a5b665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d45b7de20e33408dba1e0686931a4dfb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 996k/996k [00:00&lt;00:00, 6.31MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4d085f84af9c427d84b48d9182399e7c"
          }
        },
        "b9f71ca9bf374a92a5f4aa7875b2875d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "70eaa94bedd748ccb3b8f6c3eea49d7b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d45b7de20e33408dba1e0686931a4dfb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4d085f84af9c427d84b48d9182399e7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4633742408884c4cbc70f88619db7f8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_f9b09500165a4dd1a769e67abda825c1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3850922f01fc41d89e124ea685676d60",
              "IPY_MODEL_c989d17d92a844888863e5df2fb37e80"
            ]
          }
        },
        "f9b09500165a4dd1a769e67abda825c1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": "row wrap",
            "width": "100%",
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": "inline-flex",
            "left": null
          }
        },
        "3850922f01fc41d89e124ea685676d60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0513e418b1a43138ef4c7d679faddda",
            "_dom_classes": [],
            "description": "Epoch 0:   0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "danger",
            "max": 1977,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ed2c1d91606f4496b758d90c5154f021"
          }
        },
        "c989d17d92a844888863e5df2fb37e80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_243841f97d8248658523df8cee6d5860",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/1977 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d2ad45597ccc46ff92f61d9a12b8c9f9"
          }
        },
        "f0513e418b1a43138ef4c7d679faddda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ed2c1d91606f4496b758d90c5154f021": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": "2",
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "243841f97d8248658523df8cee6d5860": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d2ad45597ccc46ff92f61d9a12b8c9f9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2iiXnkn63Ao"
      },
      "source": [
        "import torch\r\n",
        "import time\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset,DataLoader\r\n",
        "import pandas as pd\r\n",
        "import re\r\n",
        "# !pip install transformers\r\n",
        "from transformers import BertModel, BertTokenizer\r\n",
        "from torch import cuda\r\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eKhyG8TDS-7l",
        "outputId": "afefec44-e7af-4eb7-99da-6f25ad2c9a2b"
      },
      "source": [
        "pip install pytorch-lightning"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pytorch-lightning in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (5.3.1)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.18.2)\n",
            "Requirement already satisfied: fsspec>=0.8.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (0.8.5)\n",
            "Requirement already satisfied: tensorboard>=2.2.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (2.4.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.19.4)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.3 in /usr/local/lib/python3.6/dist-packages (from pytorch-lightning) (1.7.0+cu101)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.10.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (2.23.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.36.2)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.32.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.15.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (51.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (0.4.2)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.17.2)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.12.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (1.7.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard>=2.2.0->pytorch-lightning) (3.3.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning) (0.8)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=1.3->pytorch-lightning) (3.7.4.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard>=2.2.0->pytorch-lightning) (2020.12.5)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (1.3.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.2.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.2.8)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.3.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard>=2.2.0->pytorch-lightning) (3.1.0)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2,>=1.6.3->tensorboard>=2.2.0->pytorch-lightning) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard>=2.2.0->pytorch-lightning) (3.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSsSVdOuT2WU"
      },
      "source": [
        "import pytorch_lightning as pl"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "_V75SGMM7rh6",
        "outputId": "f27e4b3f-1ee0-40b8-baf1-61f86ff32658"
      },
      "source": [
        "url = 'https://raw.githubusercontent.com/yasaswinik12/LSTM_datasets/main/tamil_offensive_full_train.csv?token=AOSGB3LH4OW2T2DFG2XVFKK743LWC'\r\n",
        "df = pd.read_csv(url, delimiter='\\t', names=['sentence','classes','nan'])\r\n",
        "df = df.drop(columns=['nan'])\r\n",
        "df.head(9)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>classes</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ippo intha trailer ah parkuravana oru like pod...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>En thalaivan yogi babu irukkaar. Padam vera le...</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Nerkonda parvai...  Sema sema sema trailer</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க</td>\n",
              "      <td>Not_offensive</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence        classes\n",
              "0                  movie vara level la Erika poguthu  Not_offensive\n",
              "1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil\n",
              "2          Padam nalla comedy padama irukum polaye..  Not_offensive\n",
              "3  karthick subburaj anne .... intha padam vetri ...  Not_offensive\n",
              "4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive\n",
              "5  ippo intha trailer ah parkuravana oru like pod...  Not_offensive\n",
              "6  En thalaivan yogi babu irukkaar. Padam vera le...  Not_offensive\n",
              "7         Nerkonda parvai...  Sema sema sema trailer  Not_offensive\n",
              "8     ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க  Not_offensive"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "THR2BY2C7u4d",
        "outputId": "c2c75eb1-01aa-4775-d4e8-ae4504a748d4"
      },
      "source": [
        "df.count()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "sentence    35139\n",
              "classes     35139\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z1OHweYg73yo",
        "outputId": "f1934775-b1c2-41be-af76-d1011c6bbee6"
      },
      "source": [
        "df['classes'].apply(len).max()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "36"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMXROKFJ77uF",
        "outputId": "c058b564-3197-49ed-b771-2b7a089c34d2"
      },
      "source": [
        "df['sentence'].apply(len).max()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MvGPUoay796S",
        "outputId": "d8af2859-ee61-473d-80b8-f9c874ccb64c"
      },
      "source": [
        "df['classes'].unique()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Not_offensive', 'not-Tamil', 'Offensive_Targeted_Insult_Other',\n",
              "       'Offensive_Targeted_Insult_Group', 'Offensive_Untargetede',\n",
              "       'Offensive_Targeted_Insult_Individual'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "PGfC25Jp8AdL",
        "outputId": "711a96c4-2e6b-4091-e386-2aff1651bd7b"
      },
      "source": [
        "encode_dict = {}\r\n",
        "\r\n",
        "def encode_cat(x):\r\n",
        "  if x not in encode_dict.keys():\r\n",
        "    encode_dict[x] = len(encode_dict)\r\n",
        "  return encode_dict[x]\r\n",
        "\r\n",
        "df['encode_cat'] = df['classes'].apply(lambda x: encode_cat(x))\r\n",
        "df.head(9)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>classes</th>\n",
              "      <th>encode_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>movie vara level la Erika poguthu</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>I love Ajith Kumar Vivegam movie inki mjy bht ...</td>\n",
              "      <td>not-Tamil</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Padam nalla comedy padama irukum polaye..</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>karthick subburaj anne .... intha padam vetri ...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>ippo intha trailer ah parkuravana oru like pod...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>En thalaivan yogi babu irukkaar. Padam vera le...</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>Nerkonda parvai...  Sema sema sema trailer</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க</td>\n",
              "      <td>Not_offensive</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sentence        classes  encode_cat\n",
              "0                  movie vara level la Erika poguthu  Not_offensive           0\n",
              "1  I love Ajith Kumar Vivegam movie inki mjy bht ...      not-Tamil           1\n",
              "2          Padam nalla comedy padama irukum polaye..  Not_offensive           0\n",
              "3  karthick subburaj anne .... intha padam vetri ...  Not_offensive           0\n",
              "4  கவுண்டர் தேவர்.சார்பாக வெற்றி பெற வாழ்த்துக்கள் 🦁  Not_offensive           0\n",
              "5  ippo intha trailer ah parkuravana oru like pod...  Not_offensive           0\n",
              "6  En thalaivan yogi babu irukkaar. Padam vera le...  Not_offensive           0\n",
              "7         Nerkonda parvai...  Sema sema sema trailer  Not_offensive           0\n",
              "8     ஏய் இது 96 யார் ஏமாத்தறீங்க? செம பின்னிட்டீங்க  Not_offensive           0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 333
        },
        "id": "1KH0SFhF8f69",
        "outputId": "88373bd8-87c0-4391-c0ff-080071e3fe0e"
      },
      "source": [
        "import seaborn as sns\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "sns.countplot(df.encode_cat)\r\n",
        "plt.xlabel('classes');"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variable as a keyword arg: x. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
            "  FutureWarning\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ0AW-1paccb"
      },
      "source": [
        "df['sentence'] = df['sentence'].apply(lambda x: x.lower())\r\n",
        "df['sentence'] = df['sentence'].apply(lambda x: re.sub(r' +', ' ',x))\r\n",
        "df['sentence'] = df['sentence'].apply(lambda x: re.sub(\"[!@#$+%*:()'-]\", ' ',x))\r\n",
        "df['sentence'] = df['sentence'].str.replace('\\d+', '')"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOc8hPDObMRj",
        "outputId": "e99818bf-2d01-4091-c618-7596177a0e5d"
      },
      "source": [
        "df['sentence'].apply(len).max()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1124"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqkk28Tv8ErH"
      },
      "source": [
        "# import imblearn\r\n",
        "# from collections import Counter\r\n",
        "# from matplotlib import pyplot\r\n",
        "# X = df['sentence']\r\n",
        "# y = df['encode_cat']\r\n",
        "# counter = Counter(y)\r\n",
        "# for k,v in counter.items():\r\n",
        "# \tper = v / len(y) * 100\r\n",
        "# \tprint('Class=%d, n=%d (%.3f%%)' % (k, v, per))\r\n",
        "# # plot the distribution\r\n",
        "# pyplot.bar(counter.keys(), counter.values())\r\n",
        "# pyplot.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XXzgjbUAbewM"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_23H_Tww8LKI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "dd3cb331bd3c4f7284476bdc6204cc39",
            "3aa39587b13643d4831ac26847f9486a",
            "d1801f975c5d43f49d91de8b6eb83dbc",
            "2c13066d6b8f407a9c6e51b8f6a5b665",
            "b9f71ca9bf374a92a5f4aa7875b2875d",
            "70eaa94bedd748ccb3b8f6c3eea49d7b",
            "d45b7de20e33408dba1e0686931a4dfb",
            "4d085f84af9c427d84b48d9182399e7c"
          ]
        },
        "outputId": "b06e856f-fc97-402b-cdfc-55b86cff4216"
      },
      "source": [
        "MAX_LEN = 512\r\n",
        "TRAIN_BATCH_SIZE = 16\r\n",
        "VALID_BATCH_SIZE = 16\r\n",
        "EPOCHS = 10\r\n",
        "LEARNING_RATE = 2e-5\r\n",
        "bert_multilingual = 'bert-base-multilingual-cased'\r\n",
        "tokenizer = BertTokenizer.from_pretrained(bert_multilingual)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd3cb331bd3c4f7284476bdc6204cc39",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=995526.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KI7LNJMd-zAp"
      },
      "source": [
        "class SentimentDataset(Dataset):\r\n",
        "\r\n",
        "  def __init__(self,sentence,encode_cat,tokenizer,max_len):\r\n",
        "    self.len = len(sentence)\r\n",
        "    self.sentence = sentence\r\n",
        "    self.encode_cat = encode_cat\r\n",
        "    self.tokenizer = tokenizer\r\n",
        "    self.max_len = max_len \r\n",
        "  \r\n",
        "\r\n",
        "  def __getitem__(self,index):\r\n",
        "    sentence = str(self.sentence[index])\r\n",
        "    sentence = \" \".join(sentence.split())\r\n",
        "    encoding = self.tokenizer.encode_plus(\r\n",
        "        sentence,\r\n",
        "        add_special_tokens = True,\r\n",
        "        max_length = self.max_len,\r\n",
        "        padding = 'max_length',\r\n",
        "        return_token_type_ids = False,\r\n",
        "        return_tensors = 'pt',\r\n",
        "        truncation = True\r\n",
        "    )\r\n",
        "    #ids = encoding['input_ids']\r\n",
        "    #mask = encoding['attention_mask']\r\n",
        "    return {\r\n",
        "        'ids' : encoding['input_ids'].flatten(),\r\n",
        "        'mask': encoding['attention_mask'].flatten(),\r\n",
        "        'targets': torch.tensor(self.encode_cat[index],dtype=torch.long)\r\n",
        "    }\r\n",
        "\r\n",
        "  def __len__(self):\r\n",
        "    return self.len"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dQpn0tEs_QMs",
        "outputId": "ac090fa6-24e5-41ee-ba3a-c3edd2282bfc"
      },
      "source": [
        "train_size = 0.9\r\n",
        "train_dataset = df.sample(frac=train_size,random_state=42).reset_index(drop=True)\r\n",
        "test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\r\n",
        "# train_dataset = train_dataset.reset_index(drop=True)\r\n",
        "\r\n",
        "print('Total no of entities in the dataset: {}'.format(df.shape))\r\n",
        "print('Train dataset:{}'.format(train_dataset.shape))\r\n",
        "print('Test dataset: {}'.format(test_dataset.shape))\r\n",
        "\r\n",
        "# training_set = SentimentDataset(train_dataset,tokenizer,MAX_LEN)\r\n",
        "# testing_set = SentimentDataset(test_dataset,tokenizer,MAX_LEN)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of entities in the dataset: (35139, 3)\n",
            "Train dataset:(31625, 3)\n",
            "Test dataset: (3514, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzrWEVPQS72d"
      },
      "source": [
        "# training_set = SentimentDataset(sentence=train_dataset['sentence'],\r\n",
        "#       encode_cat=train_dataset['encode_cat'],\r\n",
        "#       tokenizer=tokenizer,\r\n",
        "#       max_len=MAX_LEN)\r\n",
        "# testing_set = SentimentDataset(sentence=test_dataset['sentence'],\r\n",
        "#       encode_cat=test_dataset['encode_cat'],\r\n",
        "#       tokenizer=tokenizer,\r\n",
        "#       max_len=MAX_LEN)\r\n",
        "                               "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "74kBk3fl_WV8"
      },
      "source": [
        "# train_params = {'batch_size': TRAIN_BATCH_SIZE,\r\n",
        "#                 'shuffle': True,\r\n",
        "#                 'num_workers': 0\r\n",
        "#                 }\r\n",
        "\r\n",
        "# test_params = {'batch_size': VALID_BATCH_SIZE,\r\n",
        "#                 'shuffle': True,\r\n",
        "#                 'num_workers': 0\r\n",
        "#                 }\r\n",
        "\r\n",
        "# training_loader = DataLoader(training_set, **train_params)\r\n",
        "# testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1MHXWkKZwgj"
      },
      "source": [
        "weights = [0.28, 0.96, 0.99, 0.93, 0.92, 0.94]\r\n",
        "w = torch.tensor(weights)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m-10n2AR_aCX"
      },
      "source": [
        "class BERTClass(pl.LightningModule):\r\n",
        "    def __init__(self):\r\n",
        "        super(BERTClass, self).__init__()\r\n",
        "        self.l1 = BertModel.from_pretrained(\"bert-base-multilingual-cased\")\r\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\r\n",
        "        self.dropout = torch.nn.Dropout(0.3)\r\n",
        "        self.classifier = torch.nn.Linear(768, 6)\r\n",
        "\r\n",
        "        self.loss = nn.CrossEntropyLoss(weight= w)\r\n",
        "        \r\n",
        "    def forward(self, input_ids, attention_mask):\r\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\r\n",
        "        hidden_state = output_1[0]\r\n",
        "        pooler = hidden_state[:, 0]\r\n",
        "        pooler = self.pre_classifier(pooler)\r\n",
        "        pooler = torch.nn.ReLU()(pooler)\r\n",
        "        pooler = self.dropout(pooler)\r\n",
        "        output = self.classifier(pooler)\r\n",
        "        return output\r\n",
        "\r\n",
        "    def configure_optimizers(self):\r\n",
        "        optimizer = optim.Adam(params= self.parameters(),lr = LEARNING_RATE)\r\n",
        "        return optimizer\r\n",
        "\r\n",
        "    def training_step(self, batch, batch_idx):\r\n",
        "         ids = batch['ids']\r\n",
        "         mask = batch['mask']\r\n",
        "         targets = batch['targets']\r\n",
        "      \r\n",
        "         outputs = self(ids, mask)\r\n",
        "         loss = self.loss(outputs, targets)\r\n",
        "      #  tr_loss += loss.item()\r\n",
        "         big_val, big_idx = torch.max(outputs.data, dim=1)\r\n",
        "         n_correct += calcuate_accuracy(big_idx, targets)\r\n",
        "\r\n",
        "         nb_tr_steps += 1\r\n",
        "         nb_tr_examples+=targets.size(0)\r\n",
        "      \r\n",
        "      #  optimizer.zero_grad()\r\n",
        "         loss.backward()\r\n",
        "      #When using GPU\r\n",
        "      #  optimizer.step()\r\n",
        "         return {'loss' : loss}\r\n",
        "\r\n",
        "    def train_dataloader(self):\r\n",
        "         training_set = SentimentDataset(sentence=train_dataset['sentence'],\r\n",
        "                encode_cat=train_dataset['encode_cat'],\r\n",
        "                tokenizer=tokenizer,\r\n",
        "                max_len=MAX_LEN)\r\n",
        "         train_params = {'batch_size': TRAIN_BATCH_SIZE,\r\n",
        "                'shuffle': True,\r\n",
        "                'num_workers': 0\r\n",
        "                }\r\n",
        "         training_loader = DataLoader(training_set, **train_params)\r\n",
        "         return training_loader\r\n",
        "\r\n",
        "model = BERTClass()\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637,
          "referenced_widgets": [
            "4633742408884c4cbc70f88619db7f8e",
            "f9b09500165a4dd1a769e67abda825c1",
            "3850922f01fc41d89e124ea685676d60",
            "c989d17d92a844888863e5df2fb37e80",
            "f0513e418b1a43138ef4c7d679faddda",
            "ed2c1d91606f4496b758d90c5154f021",
            "243841f97d8248658523df8cee6d5860",
            "d2ad45597ccc46ff92f61d9a12b8c9f9"
          ]
        },
        "id": "QlHP7C9SABBP",
        "outputId": "537a4b9c-fb69-47b5-8cc3-3bcb374108e1"
      },
      "source": [
        "trainer = pl.Trainer(progress_bar_refresh_rate=20, gpus=1)\r\n",
        "trainer.fit(model)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "GPU available: True, used: True\n",
            "TPU available: None, using: 0 TPU cores\n",
            "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
            "\n",
            "  | Name           | Type             | Params\n",
            "----------------------------------------------------\n",
            "0 | l1             | BertModel        | 177 M \n",
            "1 | pre_classifier | Linear           | 590 K \n",
            "2 | dropout        | Dropout          | 0     \n",
            "3 | classifier     | Linear           | 4.6 K \n",
            "4 | loss           | CrossEntropyLoss | 0     \n",
            "----------------------------------------------------\n",
            "178 M     Trainable params\n",
            "0         Non-trainable params\n",
            "178 M     Total params\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4633742408884c4cbc70f88619db7f8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "UnboundLocalError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mUnboundLocalError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-988bc69afe7e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, train_dataloader, val_dataloaders, datamodule)\u001b[0m\n\u001b[1;32m    468\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'on_fit_start'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 470\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    471\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mteardown\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m         \u001b[0;31m# train or test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m         \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_or_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/accelerator.py\u001b[0m in \u001b[0;36mtrain_or_test\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 69\u001b[0;31m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     70\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    519\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_epoch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    520\u001b[0m                     \u001b[0;31m# run train epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_loop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_steps\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_epoch\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    558\u001b[0m             \u001b[0;31m# ------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"run_training_batch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m                 \u001b[0mbatch_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_training_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_idx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m             \u001b[0;31m# when returning -1 from train_step, we end epoch early\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mrun_training_batch\u001b[0;34m(self, batch, batch_idx, dataloader_idx)\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m                         \u001b[0;31m# optimizer step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_step_and_backward_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, optimizer, opt_idx, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    499\u001b[0m             \u001b[0mon_tpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_tpu\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mTPU_AVAILABLE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0musing_native_amp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0musing_native_amp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 501\u001b[0;31m             \u001b[0musing_lbfgs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_lbfgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    502\u001b[0m         )\n\u001b[1;32m    503\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/lightning.py\u001b[0m in \u001b[0;36moptimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_idx, optimizer_closure, on_tpu, using_native_amp, using_lbfgs)\u001b[0m\n\u001b[1;32m   1256\u001b[0m             \u001b[0;31m# wraps into LightingOptimizer only for running step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1257\u001b[0m             \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLightningOptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_lightning_optimizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1258\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moptimizer_closure\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1259\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1260\u001b[0m     def optimizer_zero_grad(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure, make_optimizer_step, *args, **kwargs)\u001b[0m\n\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmake_optimizer_step\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__optimizer_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprofiler_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m             \u001b[0;31m# make sure to call optimizer_closure when accumulating\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/core/optimizer.py\u001b[0m in \u001b[0;36m__optimizer_step\u001b[0;34m(self, closure, profiler_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprofiler_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m                 \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclosure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m         \u001b[0maccelerator_backend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/grad_mode.py\u001b[0m in \u001b[0;36mdecorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecorate_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/optim/adam.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclosure\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclosure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_groups\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtrain_step_and_backward_closure\u001b[0;34m()\u001b[0m\n\u001b[1;32m    711\u001b[0m                                 \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    712\u001b[0m                                 \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 713\u001b[0;31m                                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhiddens\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    714\u001b[0m                             )\n\u001b[1;32m    715\u001b[0m                             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step_and_backward\u001b[0;34m(self, split_batch, batch_idx, opt_idx, optimizer, hiddens)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"training_step_and_backward\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;31m# lightning module hook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msplit_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhiddens\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_curr_step_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/trainer/training_loop.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, split_batch, batch_idx, opt_idx, hiddens)\u001b[0m\n\u001b[1;32m    328\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_current_fx_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'training_step'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m             \u001b[0mmodel_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 330\u001b[0;31m             \u001b[0mtraining_step_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccelerator_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    331\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogger_connector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcache_logged_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mvalidation_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pytorch_lightning/accelerators/gpu_accelerator.py\u001b[0m in \u001b[0;36m_step\u001b[0;34m(self, model_step, args)\u001b[0m\n\u001b[1;32m     76\u001b[0m                 \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-19-1118c2520aa8>\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     32\u001b[0m       \u001b[0;31m#  tr_loss += loss.item()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m          \u001b[0mbig_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbig_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 34\u001b[0;31m          \u001b[0mn_correct\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mcalcuate_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbig_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m          \u001b[0mnb_tr_steps\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mUnboundLocalError\u001b[0m: local variable 'n_correct' referenced before assignment"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEqiVmieAFzc"
      },
      "source": [
        "weights = [0.28, 0.96, 0.99, 0.93, 0.92, 0.94]\r\n",
        "w = torch.tensor(weights)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYxL7isDAiGi"
      },
      "source": [
        "loss_function = nn.CrossEntropyLoss(weight= w).to(device)\r\n",
        "optimizer = optim.Adam(params= model.parameters(),lr = LEARNING_RATE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TxlqVLEEAmgw"
      },
      "source": [
        "def calcuate_accuracy(big_idx, targets):\r\n",
        "    n_correct = (big_idx==targets).sum().item()\r\n",
        "    return n_correct"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9osQKt86ApBq"
      },
      "source": [
        "import time\r\n",
        "\r\n",
        "def epoch_time(start_time, end_time):\r\n",
        "    elapsed_time = end_time - start_time\r\n",
        "    elapsed_mins = int(elapsed_time / 60)\r\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\r\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qsbho4uxAsLh",
        "outputId": "57e9ba06-6489-49f8-9abe-f4ff04251cb3"
      },
      "source": [
        "seed_val = 42\r\n",
        "torch.manual_seed(seed_val)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7f88a1ac2b58>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CG3q32CVAvMF"
      },
      "source": [
        "def train(epoch):\r\n",
        "  \r\n",
        "  tr_loss = 0\r\n",
        "  n_correct = 0\r\n",
        "  nb_tr_steps = 0\r\n",
        "  nb_tr_examples = 0\r\n",
        "  model.train()\r\n",
        "  start_time = time.time()\r\n",
        "  for _,data in enumerate(training_loader, 0):\r\n",
        "      ids = data['ids'].to(device, dtype = torch.long)\r\n",
        "      mask = data['mask'].to(device, dtype = torch.long)\r\n",
        "      targets = data['targets'].to(device, dtype = torch.long)\r\n",
        "\r\n",
        "      outputs = model(ids, mask)\r\n",
        "      loss = loss_function(outputs, targets)\r\n",
        "      tr_loss += loss.item()\r\n",
        "      big_val, big_idx = torch.max(outputs.data, dim=1)\r\n",
        "      n_correct += calcuate_accuracy(big_idx, targets)\r\n",
        "\r\n",
        "      nb_tr_steps += 1\r\n",
        "      nb_tr_examples+=targets.size(0)\r\n",
        "      \r\n",
        "      optimizer.zero_grad()\r\n",
        "      loss.backward()\r\n",
        "      #When using GPU\r\n",
        "      optimizer.step()\r\n",
        "\r\n",
        "  print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\r\n",
        "  epoch_loss = tr_loss/nb_tr_steps\r\n",
        "  epoch_accu = (n_correct*100)/nb_tr_examples\r\n",
        "  print(f\"Training Loss Epoch: {epoch_loss}\")\r\n",
        "  print(f\"Training Accuracy Epoch: {epoch_accu}\")\r\n",
        "  end_time = time.time()\r\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\r\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\r\n",
        "\r\n",
        "  return"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_F3w6xWA-W9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "outputId": "da50ab41-8c3e-49fc-942a-20b3a98d728e"
      },
      "source": [
        "for epoch in range(EPOCHS):\r\n",
        "  train(epoch)\r\n",
        "  print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-fa4b900166c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-5dae55bf9562>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m       \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m       \u001b[0;31m#When using GPU\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m       \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    130\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         allow_unreachable=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 192.00 MiB (GPU 0; 15.90 GiB total capacity; 14.51 GiB already allocated; 21.88 MiB free; 14.97 GiB reserved in total by PyTorch)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdKuZK8fBBkV"
      },
      "source": [
        "def valid(model,testing_loader):\r\n",
        "  model.eval()\r\n",
        "  n_correct = 0\r\n",
        "  n_wrong = 0\r\n",
        "  total = 0\r\n",
        "  tr_loss = 0\r\n",
        "  nb_tr_steps = 0\r\n",
        "  nb_tr_examples = 0\r\n",
        "  with torch.no_grad():\r\n",
        "    for _,data in enumerate(testing_loader,0):\r\n",
        "      ids = data['ids'].to(device,dtype = torch.long)\r\n",
        "      mask = data['mask'].to(device,dtype = torch.long)\r\n",
        "      targets = data['targets'].to(device,dtype=torch.long)\r\n",
        "      outputs = model(ids,mask).squeeze()\r\n",
        "      loss = loss_function(outputs,targets)\r\n",
        "      tr_loss += loss.item()\r\n",
        "      big_val,big_idx = torch.max(outputs.data,dim=1)\r\n",
        "      n_correct += calcuate_accuracy(big_idx,targets)\r\n",
        "      nb_tr_steps += 1\r\n",
        "      nb_tr_examples += targets.size(0)\r\n",
        "\r\n",
        "    epoch_loss = tr_loss/nb_tr_steps\r\n",
        "    epoch_accuracy = (n_correct*100)/nb_tr_examples\r\n",
        "    print(f\"Validation Loss Epoch:{epoch_loss}\")\r\n",
        "    print(f\"Validation Accuracy Epoch:{epoch_accuracy}\")\r\n",
        "\r\n",
        "    return epoch_accuracy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ab3rMF6rBkM5"
      },
      "source": [
        "acc = valid(model, testing_loader)\r\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KUFIkBb-BozE"
      },
      "source": [
        "def get_predictions(model, data_loader):\r\n",
        "  model = model.eval()\r\n",
        "  sentence = []\r\n",
        "  predictions = []\r\n",
        "  prediction_probs = []\r\n",
        "  real_values = []\r\n",
        "  with torch.no_grad():\r\n",
        "    for d in data_loader:\r\n",
        "      #texts = d[\"sentences\"]\r\n",
        "      ids = d[\"ids\"].to(device)\r\n",
        "      mask = d[\"mask\"].to(device)\r\n",
        "      targets = d[\"targets\"].to(device)\r\n",
        "      outputs = model(\r\n",
        "        input_ids=ids,\r\n",
        "        attention_mask=mask\r\n",
        "      )\r\n",
        "      _, preds = torch.max(outputs, dim=1)\r\n",
        "      #sentence.extend(texts)\r\n",
        "      predictions.extend(preds)\r\n",
        "      prediction_probs.extend(outputs)\r\n",
        "      real_values.extend(targets)\r\n",
        "  predictions = torch.stack(predictions).cpu()\r\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\r\n",
        "  real_values = torch.stack(real_values).cpu()\r\n",
        "  return sentence, predictions, prediction_probs, real_values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OXVaGFtBwnb"
      },
      "source": [
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(model,testing_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZpOXF6mUB2AG"
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\r\n",
        "print(classification_report(y_test, y_pred,zero_division=0))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}