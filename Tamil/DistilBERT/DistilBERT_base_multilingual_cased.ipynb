{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DistilBERT_base_multilingual_cased.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpi_lM3dklDn"
      },
      "source": [
        "#mporting the necessary libraries\n",
        "import torch\n",
        "import time\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "import pandas as pd\n",
        "#!pip install transformers\n",
        "from transformers import DistilBertModel, DistilBertTokenizer\n",
        "from torch import cuda\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc9yKKtbl572",
        "outputId": "21bf4b92-5710-4b0a-d802-f12d6f20b2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "df = pd.read_csv('/content/drive/My Drive/KanCMD/kannada_sentiment.csv',delimiter=',',\n",
        "                 header=None,names=['sentiment','sentence'])\n",
        "#df.sentiment = df.sentiment.apply({'Positive':0,'Negative':1,'Mixed feelings':2,'unknown state':3,'not-Kannada':4}.get)\n",
        "#df.head(9)\n",
        "my_dict = {\n",
        "    'p' : 'Positive',\n",
        "    'n' : 'Negative',\n",
        "    'm' : 'Mixed feelings',\n",
        "    'u' : 'unknown state',\n",
        "    'nk': 'not-Kannada'\n",
        "}\n",
        "\n",
        "\n",
        "encode_dict = {}\n",
        "\n",
        "def encode_cat(x):\n",
        "  if x not in encode_dict.keys():\n",
        "    encode_dict[x] = len(encode_dict)\n",
        "  return encode_dict[x]\n",
        "\n",
        "df['encode_cat'] = df['sentiment'].apply(lambda x: encode_cat(x))\n",
        "df.head(6)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>sentence</th>\n",
              "      <th>encode_cat</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Bari olu nan makla</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Negative</td>\n",
              "      <td>Sir nivu news helida hage heltiri sir</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>unknown state</td>\n",
              "      <td>Idu riyel rar</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Negative</td>\n",
              "      <td>ಕಥೆ ಅರ್ದ ಅಗಿದೆ.ಅಶ್ವತ್ತಾಮ ತನ್ಣಗಾಯಗೊಂಡ ದೇಹವನ್ನು ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Mixed feelings</td>\n",
              "      <td>ಕಥೆ ಸರಿಯಾಗಿ ತಿಳಿದುಕೊಳ್ಳಿ..... please don't wor...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Positive</td>\n",
              "      <td>Ashwathama. Vadhukkidhe.evathu. video. Nodithu...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        sentiment  ... encode_cat\n",
              "0        Negative  ...          0\n",
              "1        Negative  ...          0\n",
              "2   unknown state  ...          1\n",
              "3        Negative  ...          0\n",
              "4  Mixed feelings  ...          2\n",
              "5        Positive  ...          3\n",
              "\n",
              "[6 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnBLWHNWx11a"
      },
      "source": [
        "#Initializing the key variables which will be later used in the training\n",
        "\n",
        "MAX_LEN = 512\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VALID_BATCH_SIZE = 16\n",
        "EPOCHS = 10\n",
        "LEARNING_RATE = 2e-5\n",
        "distilbert_multilingual = 'distilbert-base-multilingual-cased'\n",
        "distilbert_base_uncased = 'distilbert-base-uncased'\n",
        "tokenizer = DistilBertTokenizer.from_pretrained(distilbert_multilingual)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3fD_4oIyiDG"
      },
      "source": [
        "class SentimentDataset(Dataset):\n",
        "\n",
        "  def __init__(self,dataframe,tokenizer,max_len):\n",
        "    self.len = len(dataframe)\n",
        "    self.data = dataframe\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len \n",
        "  \n",
        "\n",
        "  def __getitem__(self,index):\n",
        "    sentence = str(self.data.sentence[index])\n",
        "    sentence = \" \".join(sentence.split())\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "        sentence,\n",
        "        add_special_tokens = True,\n",
        "        max_length = self.max_len,\n",
        "        padding = 'max_length',\n",
        "        return_token_type_ids = False,\n",
        "        return_tensors = 'pt',\n",
        "        truncation = True\n",
        "    )\n",
        "    #ids = encoding['input_ids']\n",
        "    #mask = encoding['attention_mask']\n",
        "    return {\n",
        "        'ids' : encoding['input_ids'].flatten(),\n",
        "        'mask': encoding['attention_mask'].flatten(),\n",
        "        'targets': torch.tensor(self.data.encode_cat[index],dtype=torch.long)\n",
        "    }\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.len"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xB_mASJm0tnH",
        "outputId": "98b39e2c-5180-4ac7-a259-7849967996e5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        }
      },
      "source": [
        "#Creating the dataset and dataloader for training \n",
        "train_size = 0.9\n",
        "train_dataset = df.sample(frac=train_size,random_state=42)\n",
        "test_dataset = df.drop(train_dataset.index).reset_index(drop=True)\n",
        "train_dataset = train_dataset.reset_index(drop=True)\n",
        "\n",
        "print('Total no of entities in the dataset: {}'.format(df.shape))\n",
        "print('Train dataset:{}'.format(train_dataset.shape))\n",
        "print('Test dataset: {}'.format(test_dataset.shape))\n",
        "\n",
        "training_set = SentimentDataset(train_dataset,tokenizer,MAX_LEN)\n",
        "testing_set = SentimentDataset(test_dataset,tokenizer,MAX_LEN)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total no of entities in the dataset: (7671, 3)\n",
            "Train dataset:(6904, 3)\n",
            "Test dataset: (767, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IAJRYDR1Wjb"
      },
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V8EFGN972x96"
      },
      "source": [
        "# Fine-Tuning DistilBERT by adding a dropout and a dense layer on top of it to get the final output\n",
        "\n",
        "class DistillBERTClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(DistillBERTClass, self).__init__()\n",
        "        self.l1 = DistilBertModel.from_pretrained(\"distilbert-base-multilingual-cased\")\n",
        "        self.pre_classifier = torch.nn.Linear(768, 768)\n",
        "        self.dropout = torch.nn.Dropout(0.3)\n",
        "        self.classifier = torch.nn.Linear(768, 5)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        output_1 = self.l1(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        hidden_state = output_1[0]\n",
        "        pooler = hidden_state[:, 0]\n",
        "        pooler = self.pre_classifier(pooler)\n",
        "        pooler = torch.nn.ReLU()(pooler)\n",
        "        pooler = self.dropout(pooler)\n",
        "        output = self.classifier(pooler)\n",
        "        return output"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jdL0nZCT5Wfa"
      },
      "source": [
        "model = DistillBERTClass()\n",
        "model.to(device)\n",
        " "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mfqCZyyS5bp8"
      },
      "source": [
        "#Defining the loss function and optimizer\n",
        "loss_function = nn.CrossEntropyLoss().to(device)\n",
        "optimizer = optim.Adam(params= model.parameters(),lr = LEARNING_RATE)\n",
        "#loss_function.to(device)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTjE1aDl57nx"
      },
      "source": [
        "#Fine-Tuning DistilBERT\n",
        "def calcuate_accuracy(big_idx, targets):\n",
        "    n_correct = (big_idx==targets).sum().item()\n",
        "    return n_correct"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vs7HFEwZZV4Y"
      },
      "source": [
        "import time\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AGaOSAd7zzG"
      },
      "source": [
        "# Defining the training function on the 80% of the dataset for tuning the distilbert model\n",
        "\n",
        "def train(epoch):\n",
        "  \n",
        "  tr_loss = 0\n",
        "  n_correct = 0\n",
        "  nb_tr_steps = 0\n",
        "  nb_tr_examples = 0\n",
        "  model.train()\n",
        "  start_time = time.time()\n",
        "  for _,data in enumerate(training_loader, 0):\n",
        "      ids = data['ids'].to(device, dtype = torch.long)\n",
        "      mask = data['mask'].to(device, dtype = torch.long)\n",
        "      targets = data['targets'].to(device, dtype = torch.long)\n",
        "\n",
        "      outputs = model(ids, mask)\n",
        "      loss = loss_function(outputs, targets)\n",
        "      tr_loss += loss.item()\n",
        "      big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "      n_correct += calcuate_accuracy(big_idx, targets)\n",
        "\n",
        "      nb_tr_steps += 1\n",
        "      nb_tr_examples+=targets.size(0)\n",
        "      \n",
        "      optimizer.zero_grad()\n",
        "      loss.backward()\n",
        "      #When using GPU\n",
        "      optimizer.step()\n",
        "\n",
        "  print(f'The Total Accuracy for Epoch {epoch}: {(n_correct*100)/nb_tr_examples}')\n",
        "  epoch_loss = tr_loss/nb_tr_steps\n",
        "  epoch_accu = (n_correct*100)/nb_tr_examples\n",
        "  print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "  print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "  end_time = time.time()\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "\n",
        "  return "
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UGXZaCxBLxkS",
        "outputId": "ddc1cf9e-a357-4df9-a774-6ed5a7644f9e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 857
        }
      },
      "source": [
        "for epoch in range(EPOCHS):\n",
        "  train(epoch)\n",
        "  print()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The Total Accuracy for Epoch 0: 85.8632676709154\n",
            "Training Loss Epoch: 0.40450390463660435\n",
            "Training Accuracy Epoch: 85.8632676709154\n",
            "Epoch: 01 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 1: 89.28157589803013\n",
            "Training Loss Epoch: 0.31484513093838123\n",
            "Training Accuracy Epoch: 89.28157589803013\n",
            "Epoch: 02 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 2: 91.93221320973349\n",
            "Training Loss Epoch: 0.2405983853817883\n",
            "Training Accuracy Epoch: 91.93221320973349\n",
            "Epoch: 03 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 3: 93.1199304750869\n",
            "Training Loss Epoch: 0.19959371864442127\n",
            "Training Accuracy Epoch: 93.1199304750869\n",
            "Epoch: 04 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 4: 94.17728852838934\n",
            "Training Loss Epoch: 0.1626206540073596\n",
            "Training Accuracy Epoch: 94.17728852838934\n",
            "Epoch: 05 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 5: 95.36500579374275\n",
            "Training Loss Epoch: 0.12951855679070665\n",
            "Training Accuracy Epoch: 95.36500579374275\n",
            "Epoch: 06 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 6: 95.58227114716107\n",
            "Training Loss Epoch: 0.12565388051249707\n",
            "Training Accuracy Epoch: 95.58227114716107\n",
            "Epoch: 07 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 7: 96.37891077636154\n",
            "Training Loss Epoch: 0.09724223390744387\n",
            "Training Accuracy Epoch: 96.37891077636154\n",
            "Epoch: 08 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 8: 96.01680185399768\n",
            "Training Loss Epoch: 0.10792421460037413\n",
            "Training Accuracy Epoch: 96.01680185399768\n",
            "Epoch: 09 | Epoch Time: 3m 12s\n",
            "\n",
            "The Total Accuracy for Epoch 9: 96.78447276940904\n",
            "Training Loss Epoch: 0.08322060783366733\n",
            "Training Accuracy Epoch: 96.78447276940904\n",
            "Epoch: 10 | Epoch Time: 3m 12s\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x6XP-E3f8yRw"
      },
      "source": [
        "def valid(model,testing_loader):\n",
        "  model.eval()\n",
        "  n_correct = 0\n",
        "  n_wrong = 0\n",
        "  total = 0\n",
        "  tr_loss = 0\n",
        "  nb_tr_steps = 0\n",
        "  nb_tr_examples = 0\n",
        "  with torch.no_grad():\n",
        "    for _,data in enumerate(testing_loader,0):\n",
        "      ids = data['ids'].to(device,dtype = torch.long)\n",
        "      mask = data['mask'].to(device,dtype = torch.long)\n",
        "      targets = data['targets'].to(device,dtype=torch.long)\n",
        "      outputs = model(ids,mask).squeeze()\n",
        "      loss = loss_function(outputs,targets)\n",
        "      tr_loss += loss.item()\n",
        "      big_val,big_idx = torch.max(outputs.data,dim=1)\n",
        "      n_correct += calcuate_accuracy(big_idx,targets)\n",
        "      nb_tr_steps += 1\n",
        "      nb_tr_examples += targets.size(0)\n",
        "\n",
        "    epoch_loss = tr_loss/nb_tr_steps\n",
        "    epoch_accuracy = (n_correct*100)/nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch:{epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch:{epoch_accuracy}\")\n",
        "\n",
        "    return epoch_accuracy\n",
        "      "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0SirgRAwcOUo",
        "outputId": "77a80f41-e1bd-4f63-d5a5-9d78c8f34e8d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "print('This is the validation section to print the accuracy and see how it performs')\n",
        "print('Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch')\n",
        "\n",
        "acc = valid(model, testing_loader)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "This is the validation section to print the accuracy and see how it performs\n",
            "Here we are leveraging on the dataloader crearted for the validation dataset, the approcah is using more of pytorch\n",
            "Validation Loss Epoch:1.2726746344317992\n",
            "Validation Accuracy Epoch:58.279009126466754\n",
            "Accuracy on test data = 58.28%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V53BQH0GcOtz"
      },
      "source": [
        "def get_predictions(model, data_loader):\n",
        "  model = model.eval()\n",
        "  sentence = []\n",
        "  predictions = []\n",
        "  prediction_probs = []\n",
        "  real_values = []\n",
        "  with torch.no_grad():\n",
        "    for d in data_loader:\n",
        "      #texts = d[\"sentences\"]\n",
        "      ids = d[\"ids\"].to(device)\n",
        "      mask = d[\"mask\"].to(device)\n",
        "      targets = d[\"targets\"].to(device)\n",
        "      outputs = model(\n",
        "        input_ids=ids,\n",
        "        attention_mask=mask\n",
        "      )\n",
        "      _, preds = torch.max(outputs, dim=1)\n",
        "      #sentence.extend(texts)\n",
        "      predictions.extend(preds)\n",
        "      prediction_probs.extend(outputs)\n",
        "      real_values.extend(targets)\n",
        "  predictions = torch.stack(predictions).cpu()\n",
        "  prediction_probs = torch.stack(prediction_probs).cpu()\n",
        "  real_values = torch.stack(real_values).cpu()\n",
        "  return sentence, predictions, prediction_probs, real_values"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E3x2z768jlSx"
      },
      "source": [
        "\n",
        "y_review_texts, y_pred, y_pred_probs, y_test = get_predictions(\n",
        "  model,\n",
        "  testing_loader\n",
        ")"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mqXhIN3LxbN"
      },
      "source": [
        "class_name = ['Positive','Negative','Mixed_feelings','unknown_state','not-Kannada']"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5iHt3Jfjq2v",
        "outputId": "334475d8-b0fa-4fa0-a55d-53e486c14dfa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        }
      },
      "source": [
        "from sklearn.metrics import classification_report,confusion_matrix\n",
        "print(classification_report(y_test, y_pred, target_names=class_name,zero_division=0))"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "                precision    recall  f1-score   support\n",
            "\n",
            "      Positive       0.59      0.59      0.59       152\n",
            "      Negative       0.36      0.37      0.36        84\n",
            "Mixed_feelings       0.16      0.08      0.11        75\n",
            " unknown_state       0.68      0.74      0.71       347\n",
            "   not-Kannada       0.56      0.58      0.57       109\n",
            "\n",
            "      accuracy                           0.58       767\n",
            "     macro avg       0.47      0.47      0.47       767\n",
            "  weighted avg       0.56      0.58      0.57       767\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}